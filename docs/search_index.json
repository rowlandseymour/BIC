[["index.html", "Bayesian Inference and Computation Practicalities 0.1 Module aims 0.2 Module structure 0.3 Assessment 0.4 Getting help 0.5 Recommended books and videos 0.6 Common Distributions", " Bayesian Inference and Computation Dr Rowland Seymour Semester 2, 2023 Practicalities 0.1 Module aims The module aims to give you an overview of the Bayesian paradigm. By the end of the course, you should Be able to conceptualise a Bayesian approach for statistics Be able to derive posterior and posterior predictive distributions for uni- and multivariate models Identify suitable prior distributions and understand how the choice of prior distribution may affect the final result Understand the principles of Markov Chain Monte Carlo and be able to construct an MCMC algorithm 0.2 Module structure The module is split between theory and programming. Each week (excluding week 6) will have two lectures and two computer labs. 0.3 Assessment The module is 55% coursework and 45% exam. The exam will last 1h 30m and take place during the summer exam period. More details about the coursework will be announced during the semester. 0.4 Getting help There are lots of ways of getting help throughout the module. You can visit my office hour (Watson 317) on ….. or email me at r.g.seymour@bham.ac.uk. Each week, there will also be a problem class. 0.5 Recommended books and videos No books are required for this course and the whole material is contained in these notes. However, you may find it useful to use other resources in your studies. I recommend the following: A First Course in Bayesian Statistical Methods - Peter D. Hoff. This is a short book that covers the basics of Bayesian inference and computation. To the point and well written, it’s a useful place to look topics up. Bayesian Data Analysis - Andrew Gelman, John Carlin, Hal Stern, David Dunson, Aki Vehtari, and Donald Rubin. This is a thorough book explaining everything you’d need to know to carry out Bayesian data analysis. It’s a fairly look and in-depth book, but the authors are authoritative and give good advice throughout. Example code on the website is in R, Python and Stan. Statistical Rethinking - Richard McElrath. This book provides a friendly intuitive understanding of Bayesian inference and computation. Aimed at social and natural scientists, it has less theory that the other two books but is perhaps more approachable. A set of video lectures for this book can be found on YouTube. 0.6 Common Distributions For many Bayesian inference problems, it is useful to be able to identify probability density functions up to proportionality. Some common density functions are given below. Normal distribution. \\[ \\pi(x \\mid \\mu, \\sigma^2) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\exp\\left\\{-\\frac{1}{2\\sigma^2}(x-\\mu)^2\\right\\} \\qquad x, \\mu, \\sigma \\in\\mathbb{R} \\] Beta distribution. \\[ \\pi(x\\mid \\alpha, \\beta) = \\frac{1}{\\hbox{Beta}(\\alpha, \\beta)}x^{\\alpha-1}(1-x)^{\\beta - 1} \\qquad \\alpha, \\beta &gt; 0, \\,x \\in [0, 1], \\] Gamma distribution. \\[ \\pi(x\\mid \\alpha, \\beta) = \\frac{\\beta^\\alpha}{\\Gamma(\\alpha)}x^{\\alpha - 1}e^{-\\beta x} \\] Exponential distribution. \\[ f(x \\mid \\lambda) = \\lambda e^{-\\lambda x} \\qquad \\lambda, x &gt; 0 \\] Poisson distribution. \\[ \\pi(x = k \\mid \\lambda) = \\frac{\\lambda^k e^{-\\lambda}}{k!} \\qquad k \\in \\{1, 2, \\ldots\\}, \\, \\lambda &gt; 0 \\] Binomial distribution. \\[ \\pi(x = k \\mid N, p) = \\begin{pmatrix} N \\\\ k\\end{pmatrix} p^k (1-p)^{N-k} \\qquad k \\in \\{1, \\ldots, N\\}, p \\in [0, 1] \\] "]]
