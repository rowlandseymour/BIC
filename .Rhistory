loglike.current   <- log.likelihood(x, alpha.current, beta.current)
#Compute Log acceptance probability
log.p.acc <- loglike.prop - loglike.current +
dgamma(alpha.prop, 1, 0.01, log = TRUE) - dgamma(alpha.current, 1, 0.01, log = TRUE)
#Accept/Reject
u <- runif(1)
if(log(u) < log.p.acc){
alpha.current <- alpha.prop
}
}
#Update beta using a Gibbs Sampler
# beta.current <- rgamma(1, length(x)*alpha.current + 1, sum(1/x) + 0.01)
#Store Current Value
alpha.store[i] <- alpha.current
beta.store[i] <- beta.current
}
#Plot trace plots
plot(alpha.store, type = 'l')
plot(beta.store, type = 'l')
#Investigate posterior
# hist(p.store, freq = FALSE, main = "", xlab = expression(p))
# mean(p.store)
# quantile(p.store, c(0.025, 0.975))
#The Posterior Distribution
# \pi(alpha, beta \mid x) \propto \beta^(N*alpha)/Gamma(alpha)*
#            prod(x)^(-alpha -1)*e^(-beta(sum(1/x)))*
#            alpha^{a-1}e^(-b*alpha)beta^{c-1}*e^(-d*beta)
# The full conditionals are
# \pi(\alpha \mid \beta , x) \propto \beta^(N*alpha)/Gamma(alpha)*
#            prod(x)^(-alpha -1)*alpha^{a-1}e^(-b*alpha)
# \pi(\beta \mid \alpha , x) \propto\beta^(N*alpha)e^(-beta(sum(1/x)))beta^{c-1}*e^(-d*beta)
# This has a nice closed form \beta \mid \alpha , x \sim Gamma(N*\alpha + c, sum(1/x) + d)
# Function to evaluate loglikelihood --------------------------------------
log.likelihood <- function(x, alpha, beta){
log.value <- (length(x)*alpha)*log(beta)- length(x)*lgamma(alpha) + (-alpha -1)*log(sum(x)) - beta*(sum(1/x))
return(log.value)
}
# MCMC Sampler ------------------------------------------------------------
#Initialise Values
x <- 1/rgamma(100, 4, 6) #Generate some data
n.iter <- 10000 #number of iterations
alpha.current <- 4 #initial value for alpha
beta.current <- 6 #initial value for beta
alpha.store <- numeric(n.iter) #empty vector to store alpha at each iteration
beta.store <- numeric(n.iter) #empty vecotr to store beta at each iteration
#Run MCMC For Loop
for(i in 1:n.iter){
#Update alpha using MHRW
# alpha.prop <- rnorm(1, alpha.current, 0.1)
#
# if(alpha.prop > 0){
#   #Compute current and prop loglikelihood
#   loglike.prop      <- log.likelihood(x, alpha.prop, beta.current)
#   loglike.current   <- log.likelihood(x, alpha.current, beta.current)
#
#   #Compute Log acceptance probability
#   log.p.acc <- loglike.prop - loglike.current +
#     dgamma(alpha.prop, 1, 0.01, log = TRUE) - dgamma(alpha.current, 1, 0.01, log = TRUE)
#
#
#   #Accept/Reject
#   u <- runif(1)
#   if(log(u) < log.p.acc){
#     alpha.current <- alpha.prop
#   }
# }
#Update beta using a Gibbs Sampler
beta.current <- rgamma(1, length(x)*alpha.current + 1, sum(1/x) + 0.01)
#Store Current Value
alpha.store[i] <- alpha.current
beta.store[i] <- beta.current
}
#Plot trace plots
plot(alpha.store, type = 'l')
plot(beta.store, type = 'l')
#Investigate posterior
# hist(p.store, freq = FALSE, main = "", xlab = expression(p))
# mean(p.store)
# quantile(p.store, c(0.025, 0.975))
#The Posterior Distribution
# \pi(alpha, beta \mid x) \propto \beta^(N*alpha)/Gamma(alpha)*
#            prod(x)^(-alpha -1)*e^(-beta(sum(1/x)))*
#            alpha^{a-1}e^(-b*alpha)beta^{c-1}*e^(-d*beta)
# The full conditionals are
# \pi(\alpha \mid \beta , x) \propto \beta^(N*alpha)/Gamma(alpha)*
#            prod(x)^(-alpha -1)*alpha^{a-1}e^(-b*alpha)
# \pi(\beta \mid \alpha , x) \propto\beta^(N*alpha)e^(-beta(sum(1/x)))beta^{c-1}*e^(-d*beta)
# This has a nice closed form \beta \mid \alpha , x \sim Gamma(N*\alpha + c, sum(1/x) + d)
# Function to evaluate loglikelihood --------------------------------------
log.likelihood <- function(x, alpha, beta){
log.value <- (length(x)*alpha)*log(beta)- length(x)*lgamma(alpha) + (-alpha -1)*log(sum(x)) - beta*(sum(1/x))
return(log.value)
}
# MCMC Sampler ------------------------------------------------------------
#Initialise Values
x <- 1/rgamma(100, 4, 6) #Generate some data
n.iter <- 10000 #number of iterations
alpha.current <- 4 #initial value for alpha
beta.current <- 6 #initial value for beta
alpha.store <- numeric(n.iter) #empty vector to store alpha at each iteration
beta.store <- numeric(n.iter) #empty vecotr to store beta at each iteration
#Run MCMC For Loop
for(i in 1:n.iter){
#Update alpha using MHRW
alpha.prop <- rnorm(1, alpha.current, 0.1)
if(alpha.prop > 0){
#Compute current and prop loglikelihood
loglike.prop      <- log.likelihood(x, alpha.prop, beta.current)
loglike.current   <- log.likelihood(x, alpha.current, beta.current)
#Compute Log acceptance probability
log.p.acc <- loglike.prop - loglike.current +
dgamma(alpha.prop, 1, 0.01, log = TRUE) - dgamma(alpha.current, 1, 0.01, log = TRUE)
#Accept/Reject
u <- runif(1)
if(log(u) < log.p.acc){
alpha.current <- alpha.prop
}
}
#Update beta using a Gibbs Sampler
# beta.current <- rgamma(1, length(x)*alpha.current + 1, sum(1/x) + 0.01)
#Store Current Value
alpha.store[i] <- alpha.current
beta.store[i] <- beta.current
}
#Plot trace plots
plot(alpha.store, type = 'l')
plot(beta.store, type = 'l')
#Investigate posterior
# hist(p.store, freq = FALSE, main = "", xlab = expression(p))
# mean(p.store)
# quantile(p.store, c(0.025, 0.975))
#The Posterior Distribution
# \pi(alpha, beta \mid x) \propto \beta^(N*alpha)/Gamma(alpha)*
#            prod(x)^(-alpha -1)*e^(-beta(sum(1/x)))*
#            alpha^{a-1}e^(-b*alpha)beta^{c-1}*e^(-d*beta)
# The full conditionals are
# \pi(\alpha \mid \beta , x) \propto \beta^(N*alpha)/Gamma(alpha)*
#            prod(x)^(-alpha -1)*alpha^{a-1}e^(-b*alpha)
# \pi(\beta \mid \alpha , x) \propto\beta^(N*alpha)e^(-beta(sum(1/x)))beta^{c-1}*e^(-d*beta)
# This has a nice closed form \beta \mid \alpha , x \sim Gamma(N*\alpha + c, sum(1/x) + d)
# Function to evaluate loglikelihood --------------------------------------
log.likelihood <- function(x, alpha, beta){
log.value <- (length(x)*alpha)*log(beta)- length(x)*lgamma(alpha) + (-alpha -1)*sum(log(x)) - beta*(sum(1/x))
return(log.value)
}
# MCMC Sampler ------------------------------------------------------------
#Initialise Values
x <- 1/rgamma(100, 4, 6) #Generate some data
n.iter <- 10000 #number of iterations
alpha.current <- 4 #initial value for alpha
beta.current <- 6 #initial value for beta
alpha.store <- numeric(n.iter) #empty vector to store alpha at each iteration
beta.store <- numeric(n.iter) #empty vecotr to store beta at each iteration
#Run MCMC For Loop
for(i in 1:n.iter){
#Update alpha using MHRW
alpha.prop <- rnorm(1, alpha.current, 0.1)
if(alpha.prop > 0){
#Compute current and prop loglikelihood
loglike.prop      <- log.likelihood(x, alpha.prop, beta.current)
loglike.current   <- log.likelihood(x, alpha.current, beta.current)
#Compute Log acceptance probability
log.p.acc <- loglike.prop - loglike.current +
dgamma(alpha.prop, 1, 0.01, log = TRUE) - dgamma(alpha.current, 1, 0.01, log = TRUE)
#Accept/Reject
u <- runif(1)
if(log(u) < log.p.acc){
alpha.current <- alpha.prop
}
}
#Update beta using a Gibbs Sampler
# beta.current <- rgamma(1, length(x)*alpha.current + 1, sum(1/x) + 0.01)
#Store Current Value
alpha.store[i] <- alpha.current
beta.store[i] <- beta.current
}
#Plot trace plots
plot(alpha.store, type = 'l')
plot(beta.store, type = 'l')
#Investigate posterior
# hist(p.store, freq = FALSE, main = "", xlab = expression(p))
# mean(p.store)
# quantile(p.store, c(0.025, 0.975))
#The Posterior Distribution
# \pi(alpha, beta \mid x) \propto \beta^(N*alpha)/Gamma(alpha)*
#            prod(x)^(-alpha -1)*e^(-beta(sum(1/x)))*
#            alpha^{a-1}e^(-b*alpha)beta^{c-1}*e^(-d*beta)
# The full conditionals are
# \pi(\alpha \mid \beta , x) \propto \beta^(N*alpha)/Gamma(alpha)*
#            prod(x)^(-alpha -1)*alpha^{a-1}e^(-b*alpha)
# \pi(\beta \mid \alpha , x) \propto\beta^(N*alpha)e^(-beta(sum(1/x)))beta^{c-1}*e^(-d*beta)
# This has a nice closed form \beta \mid \alpha , x \sim Gamma(N*\alpha + c, sum(1/x) + d)
# Function to evaluate loglikelihood --------------------------------------
log.likelihood <- function(x, alpha, beta){
log.value <- (length(x)*alpha)*log(beta)- length(x)*lgamma(alpha) + (-alpha -1)*sum(log(x)) - beta*(sum(1/x))
return(log.value)
}
# MCMC Sampler ------------------------------------------------------------
#Initialise Values
x <- 1/rgamma(100, 4, 6) #Generate some data
n.iter <- 10000 #number of iterations
alpha.current <- 4 #initial value for alpha
beta.current <- 6 #initial value for beta
alpha.store <- numeric(n.iter) #empty vector to store alpha at each iteration
beta.store <- numeric(n.iter) #empty vecotr to store beta at each iteration
#Run MCMC For Loop
for(i in 1:n.iter){
#Update alpha using MHRW
alpha.prop <- rnorm(1, alpha.current, 0.1)
if(alpha.prop > 0){
#Compute current and prop loglikelihood
loglike.prop      <- log.likelihood(x, alpha.prop, beta.current)
loglike.current   <- log.likelihood(x, alpha.current, beta.current)
#Compute Log acceptance probability
log.p.acc <- loglike.prop - loglike.current +
dgamma(alpha.prop, 1, 0.01, log = TRUE) - dgamma(alpha.current, 1, 0.01, log = TRUE)
#Accept/Reject
u <- runif(1)
if(log(u) < log.p.acc){
alpha.current <- alpha.prop
}
}
#Update beta using a Gibbs Sampler
beta.current <- rgamma(1, length(x)*alpha.current + 1, sum(1/x) + 0.01)
#Store Current Value
alpha.store[i] <- alpha.current
beta.store[i] <- beta.current
}
#Plot trace plots
plot(alpha.store, type = 'l')
plot(beta.store, type = 'l')
#Investigate posterior
# hist(p.store, freq = FALSE, main = "", xlab = expression(p))
# mean(p.store)
# quantile(p.store, c(0.025, 0.975))
#The Posterior Distribution
# \pi(alpha, beta \mid x) \propto \beta^(N*alpha)/Gamma(alpha)*
#            prod(x)^(-alpha -1)*e^(-beta(sum(1/x)))*
#            alpha^{a-1}e^(-b*alpha)beta^{c-1}*e^(-d*beta)
# The full conditionals are
# \pi(\alpha \mid \beta , x) \propto \beta^(N*alpha)/Gamma(alpha)*
#            prod(x)^(-alpha -1)*alpha^{a-1}e^(-b*alpha)
# \pi(\beta \mid \alpha , x) \propto\beta^(N*alpha)e^(-beta(sum(1/x)))beta^{c-1}*e^(-d*beta)
# This has a nice closed form \beta \mid \alpha , x \sim Gamma(N*\alpha + c, sum(1/x) + d)
# Function to evaluate loglikelihood --------------------------------------
log.likelihood <- function(x, alpha, beta){
log.value <- (length(x)*alpha)*log(beta)- length(x)*lgamma(alpha) + (-alpha -1)*sum(log(x)) - beta*(sum(1/x))
return(log.value)
}
# MCMC Sampler ------------------------------------------------------------
#Initialise Values
x <- 1/rgamma(100, 4, 6) #Generate some data
n.iter <- 100000 #number of iterations
alpha.current <- 4 #initial value for alpha
beta.current <- 6 #initial value for beta
alpha.store <- numeric(n.iter) #empty vector to store alpha at each iteration
beta.store <- numeric(n.iter) #empty vecotr to store beta at each iteration
#Run MCMC For Loop
for(i in 1:n.iter){
#Update alpha using MHRW
alpha.prop <- rnorm(1, alpha.current, 0.1)
if(alpha.prop > 0){
#Compute current and prop loglikelihood
loglike.prop      <- log.likelihood(x, alpha.prop, beta.current)
loglike.current   <- log.likelihood(x, alpha.current, beta.current)
#Compute Log acceptance probability
log.p.acc <- loglike.prop - loglike.current +
dgamma(alpha.prop, 1, 0.01, log = TRUE) - dgamma(alpha.current, 1, 0.01, log = TRUE)
#Accept/Reject
u <- runif(1)
if(log(u) < log.p.acc){
alpha.current <- alpha.prop
}
}
#Update beta using a Gibbs Sampler
beta.current <- rgamma(1, length(x)*alpha.current + 1, sum(1/x) + 0.01)
#Store Current Value
alpha.store[i] <- alpha.current
beta.store[i] <- beta.current
}
#Plot trace plots
plot(alpha.store, type = 'l')
plot(beta.store, type = 'l')
#Investigate posterior
# hist(p.store, freq = FALSE, main = "", xlab = expression(p))
# mean(p.store)
# quantile(p.store, c(0.025, 0.975))
#Investigate posterior
plot(alpha.store, beta.store)
lambda <- rnorm(10, 0, 4)
lambda
comparisons <- BSBT::simulate_comparisons(1000, lambda)
comparisons <- BSBT::simulate_comparisons(1000, lambda, 0)
ssr.func <- function(BTmoutcome){
#Input: BTm Model
#Outcome: SSR value
#Description: Calculates a scale separation reliability value from a BTm model.
btability <- BTabilities(BTmoutcome) #Ability estimates and their standard errors
btability <- data.frame(btabil)
std.error.btability <- btabil$s.e. #Standard errors
mse <- mean(std.error.btability^2) #MSE of the standard errors
SSR = (var(BTmoutcome$coefficients) - mse)/var(BTmoutcome$coefficients) #SSR value
return(SSR)
}
head(comparisons$results)
BTmoutcome <- BradleyTerry2::BTm(outcome = comparisons$results$result, player1 = comparisons$results$area1, player2 = comparisons$results$area2)
BTmoutcome$coefficients
lambda
btability <- BTabilities(BTmoutcome) #Ability estimates and their standard errors
library(BradleyTerry2)
btability <- BTabilities(BTmoutcome) #Ability estimates and their standard errors
btability <- data.frame(btabil)
btability <- data.frame(btabililty)
btability <- data.frame(btability)
std.error.btability <- btabil$s.e. #Standard errors
mse <- mean(std.error.btability^2) #MSE of the standard errors
std.error.btability <- btability$s.e. #Standard errors
mse <- mean(std.error.btability^2) #MSE of the standard errors
SSR = (var(BTmoutcome$coefficients) - mse)/var(BTmoutcome$coefficients) #SSR value
SSR
mse
lambda <- rnorm(10, 0, 4)
comparisons <- BSBT::simulate_comparisons(10000, lambda, 0)
lambda <- rnorm(10, 0, 4)
comparisons <- BSBT::simulate_comparisons(10000, lambda, 0)
BTmoutcome <- BradleyTerry2::BTm(outcome = comparisons$results$result, player1 = comparisons$results$area1, player2 = comparisons$results$area2)
ssr.func <- function(BTmoutcome){
#Input: BTm Model
#Outcome: SSR value
#Description: Calculates a scale separation reliability value from a BTm model.
btability <- BTabilities(BTmoutcome) #Ability estimates and their standard errors
btability <- data.frame(btability)
std.error.btability <- btability$s.e. #Standard errors
mse <- mean(std.error.btability^2) #MSE of the standard errors
SSR = (var(BTmoutcome$coefficients) - mse)/var(BTmoutcome$coefficients) #SSR value
return(SSR)
}
btability <- BTabilities(BTmoutcome) #Ability estimates and their standard errors
btability <- BradleyTerry2::BTabilities(BTmoutcome) #Ability estimates and their standard errors
lambda <- rnorm(10, 0, 4)
comparisons <- BSBT::simulate_comparisons(10000, lambda, 0)
head(comparisons$results)
btability <- BradleyTerry2::BTabilities(BTmoutcome) #Ability estimates and their standard errors
btability
btability <- data.frame(btability)
std.error.btability <- btability$s.e. #Standard errors
mse <- mean(std.error.btability^2) #MSE of the standard errors
SSR = (var(BTmoutcome$coefficients) - mse)/var(BTmoutcome$coefficients) #SSR value
SSR
mse
plot(lambda - mean(lambda), btability)
plot(lambda - mean(lambda), btability$ability)
abline(0, 1)
lambda <- rnorm(10, 0, 4)
comparisons <- BSBT::simulate_comparisons(10000, lambda, 0)
BTmoutcome <- BradleyTerry2::BTm(outcome = comparisons$results$result, player1 = comparisons$results$area1, player2 = comparisons$results$area2)
btability <- BradleyTerry2::BTabilities(BTmoutcome) #Ability estimates and their standard errors
plot(lambda - mean(lambda), btability$ability)
btability <- data.frame(btability)
plot(lambda - mean(lambda), btability$ability)
abline(0, 1)
plot(lambda, btability$ability)
abline(0, 1)
plot(lambda, btability$ability - mean(btability$ability))
abline(0, 1)
plot(lambda - mean(lambda), btability$ability - mean(btability$ability))
abline(0, 1)
btability <- BradleyTerry2::BTabilities(BTmoutcome) #Ability estimates and their standard errors
btability <- data.frame(btability)
std.error.btability <- btability$s.e. #Standard errors
mse <- mean(std.error.btability^2) #MSE of the standard errors
mse
SSR
SSR = (var(BTmoutcome$coefficients) - mse)/var(BTmoutcome$coefficients) #SSR value
SSR
lambda <- rnorm(10, 0, 8)
comparisons <- BSBT::simulate_comparisons(10000, lambda, 0)
BTmoutcome <- BradleyTerry2::BTm(outcome = comparisons$results$result, player1 = comparisons$results$area1, player2 = comparisons$results$area2)
ssr.func <- function(BTmoutcome){
#Input: BTm Model
#Outcome: SSR value
#Description: Calculates a scale separation reliability value from a BTm model.
btability <- BradleyTerry2::BTabilities(BTmoutcome) #Ability estimates and their standard errors
btability <- data.frame(btability)
std.error.btability <- btability$s.e. #Standard errors
mse <- mean(std.error.btability^2) #MSE of the standard errors
SSR = (var(BTmoutcome$coefficients) - mse)/var(BTmoutcome$coefficients) #SSR value
return(SSR)
}
ssr.func(BTmoutcome)
lambda
btability <- BradleyTerry2::BTabilities(BTmoutcome) #Ability estimates and their standard errors
btability
plot(lambda - mean(lambda), btability$ability - mean(btability$ability))
btability <- data.frame(btability)
plot(lambda - mean(lambda), btability$ability - mean(btability$ability))
abline(0, 1)
hist(lambda)
hist(btability$ability)
comparisons <- BSBT::simulate_comparisons(100000, lambda, 0)
BTmoutcome <- BradleyTerry2::BTm(outcome = comparisons$results$result, player1 = comparisons$results$area1, player2 = comparisons$results$area2)
ssr.func <- function(BTmoutcome){
#Input: BTm Model
#Outcome: SSR value
#Description: Calculates a scale separation reliability value from a BTm model.
btability <- BradleyTerry2::BTabilities(BTmoutcome) #Ability estimates and their standard errors
btability <- data.frame(btability)
std.error.btability <- btability$s.e. #Standard errors
mse <- mean(std.error.btability^2) #MSE of the standard errors
SSR = (var(BTmoutcome$coefficients) - mse)/var(BTmoutcome$coefficients) #SSR value
return(SSR)
}
ssr.func(BTmoutcome)
btability <- data.frame(btability)
btability <- BradleyTerry2::BTabilities(BTmoutcome) #Ability estimates and their standard errors
btability <- data.frame(btability)
std.error.btability <- btability$s.e. #Standard errors
mse <- mean(std.error.btability^2) #MSE of the standard errors
mse
data.frame(btability)
exp(22)/(exp(22) + exp(0))
lambda
lambda <- rnorm(10, 0, 8)
comparisons <- BSBT::simulate_comparisons(10000, lambda, 0)
BTmoutcome <- BradleyTerry2::BTm(outcome = comparisons$results$result, player1 = comparisons$results$area1, player2 = comparisons$results$area2)
ssr.func <- function(BTmoutcome){
#Input: BTm Model
#Outcome: SSR value
#Description: Calculates a scale separation reliability value from a BTm model.
btability <- BradleyTerry2::BTabilities(BTmoutcome) #Ability estimates and their standard errors
btability <- data.frame(btability)
std.error.btability <- btability$s.e. #Standard errors
mse <- mean(std.error.btability^2) #MSE of the standard errors
SSR = (var(BTmoutcome$coefficients) - mse)/var(BTmoutcome$coefficients) #SSR value
return(SSR)
}
ssr.func(BTmoutcome)
btability <- data.frame(btability)
qvcalc::qvcalc(btability)
btability <- data.frame(btability)
qvcalc::qvcalc(btability)
help(qvcalc)
btability <- BradleyTerry2::BTabilities(BTmoutcome) #Ability estimates and their standard errors
qvcalc::qvcalc(btability)
set.seed(1234)   #to reproduce
scaling.c <- 3/2         #set c
y <- runif(1, 0, 2)    #sample Y ~ Q
p <- 3/4*y*(2-y) #compute pi(y)
k <- p/(scaling.c*1/2)     #compute k
u <- runif(1)    #sample U ~ U[0, 1]
ifelse(u < k, 'accept', 'reject') #Accept if  u < k
#Create nice plot
a <- seq(0, 2, 0.01)
b <- 3/4*a*(2-a)
scaling.c  <- scaling.c*rep(1, length(a))
plot(a, b, ylim = c(0, scaling.c), type = 'l')
set.seed(1234)   #to reproduce
scaling.c <- 3/2         #set c
scaling.c
y <- runif(1, 0, 2)    #sample Y ~ Q
p <- 3/4*y*(2-y) #compute pi(y)
k <- p/(scaling.c*1/2)     #compute k
u <- runif(1)    #sample U ~ U[0, 1]
ifelse(u < k, 'accept', 'reject') #Accept if  u < k
#Create nice plot
a <- seq(0, 2, 0.01)
b <- 3/4*a*(2-a)
scaling.c  <- scaling.c*rep(1, length(a))
plot(a, b, ylim = c(0, scaling.c), type = 'l')
ylim
c
9
scaling.x
scaling.c
x <- seq(0, 6, 0.01)
y <- dgamma(x, 3, 2)
sacling.c <- 2^3/gamma(3)*4*exp(-4)
q <- dexp(x, 1)
q
x <- seq(0, 6, 0.01)
scaling.
y <- dgamma(x, 3, 2)
scaling.c <- 2^3/gamma(3)*4*exp(-4)
q <- dexp(x, 1)
plot(x, y, type = 'l')
scaling.c <- 2^3/gamma(3)*4*exp(-4)
x <- seq(0, 6, 0.01)
y <- dgamma(x, 3, 2)
scaling.c <- 2^3/gamma(3)*4*exp(-4)
q <- dexp(x, 1)
plot(x, y, type = 'l')
lines(x, q/scaling.c, col = 2, lty = 2)
lines(x, q*scaling.c, col = 2, lty = 2)
z <- 2^3/gamma(3)*x^2*exp(-2*x)
plot(x, z, type = 'l')
x[which.max(x)]
x[which.max(z)]
which.max(z)
max(z)
z <- 2^3/gamma(3)*x^2*exp(-*x)
plot(x, z, type = 'l')
z <- 2^3/gamma(3)*x^2*exp(-x)
plot(x, z, type = 'l')
x[which.max(z)]
max(z)
scaling.q
scaling.c
2^3/gamma(3)*4*exp(-4)
scaling.c <- 2^3/gamma(3)*4*exp(-2)
q <- dexp(x, 1)
plot(x, y, type = 'l')
lines(x, q*scaling.c, col = 2, lty = 2)
