(beta - 1)*log((1-lambda.prop)/(1-lambda)) +
(lambda - lambda.prop)*sum.x
if(log(runif(1)) < log.p.acc)
lambda <- lambda.prop
}
lambda.store[i] <- lambda
}
plot(lambda.store, type = 'l', xlab = "iteration", ylab = expression(lambda))
lambda <- 0.5
n.iter <- 10000
lambda.store <- numeric(n.iter)
sum.x <- 36.6
N <- 20
alpha <- 1
beta <- 1
for(i in 1:n.iter){
lambda.prop <- rnorm(1, lambda, 0.1)
#Check lambda \in [0, 1]
if(lambda.prop > 0 & lambda.prop < 1){
log.p.acc <- (N + alpha - 1)*log(lambda.prop/lambda) +
(beta - 1)*log((1-lambda.prop)/(1-lambda)) +
(lambda - lambda.prop)*sum.x
if(log(runif(1)) < log.p.acc)
lambda <- lambda.prop
}
lambda.store[i] <- lambda
}
plot(lambda.store, type = 'l', xlab = "iteration", ylab = expression(lambda))
abline(h=0.3, col = 2) #the value I used to simulate the data
x <- rexp(20, 0.3)
lambda <- 0.5
n.iter <- 10000
lambda.store <- numeric(n.iter)
sum.x <- 36.6
N <- 20
alpha <- 1
beta <- 1
for(i in 1:n.iter){
lambda.prop <- rnorm(1, lambda, 0.1)
#Check lambda \in [0, 1]
if(lambda.prop > 0 & lambda.prop < 1){
log.p.acc <- (N + alpha - 1)*log(lambda.prop/lambda) +
(beta - 1)*log((1-lambda.prop)/(1-lambda)) +
(lambda - lambda.prop)*sum.x
if(log(runif(1)) < log.p.acc)
lambda <- lambda.prop
}
lambda.store[i] <- lambda
}
plot(lambda.store, type = 'l', xlab = "iteration", ylab = expression(lambda))
abline(h=0.3, col = 2) #the value I used to simulate the data
x <- rexp(20, 0.3)
lambda <- 0.5
n.iter <- 10000
lambda.store <- numeric(n.iter)
sum.x <- 36.6
N <- 20
alpha <- 1
beta <- 1
for(i in 1:n.iter){
lambda.prop <- rnorm(1, lambda, 0.1)
#Check lambda \in [0, 1]
if(lambda.prop > 0 & lambda.prop < 1){
log.p.acc <- (N + alpha - 1)*log(lambda.prop/lambda) +
(beta - 1)*log((1-lambda.prop)/(1-lambda)) -
(lambda - lambda.prop)*sum.x
if(log(runif(1)) < log.p.acc)
lambda <- lambda.prop
}
lambda.store[i] <- lambda
}
plot(lambda.store, type = 'l', xlab = "iteration", ylab = expression(lambda))
abline(h=0.3, col = 2) #the value I used to simulate the data
x <- rexp(20, 0.3)
lambda <- 0.5
n.iter <- 10000
lambda.store <- numeric(n.iter)
sum.x <- 36.6
N <- 20
alpha <- 1
beta <- 1
for(i in 1:n.iter){
lambda.prop <- rnorm(1, lambda, 0.1)
#Check lambda \in [0, 1]
if(lambda.prop > 0 & lambda.prop < 1){
log.p.acc <- (N + alpha - 1)*log(lambda.prop/lambda) +
(beta - 1)*log((1-lambda.prop)/(1-lambda)) +
(lambda - lambda.prop)*sum.x
if(log(runif(1)) < log.p.acc)
lambda <- lambda.prop
}
lambda.store[i] <- lambda
}
plot(lambda.store, type = 'l', xlab = "iteration", ylab = expression(lambda))
abline(h=0.3, col = 2) #the value I used to simulate the data
sum(x)
lambda <- 0.5
n.iter <- 10000
lambda.store <- numeric(n.iter)
sum.x <- 67.6
N <- 20
alpha <- 1
beta <- 1
for(i in 1:n.iter){
lambda.prop <- rnorm(1, lambda, 0.1)
#Check lambda \in [0, 1]
if(lambda.prop > 0 & lambda.prop < 1){
log.p.acc <- (N + alpha - 1)*log(lambda.prop/lambda) +
(beta - 1)*log((1-lambda.prop)/(1-lambda)) +
(lambda - lambda.prop)*sum.x
if(log(runif(1)) < log.p.acc)
lambda <- lambda.prop
}
lambda.store[i] <- lambda
}
plot(lambda.store, type = 'l', xlab = "iteration", ylab = expression(lambda))
abline(h=0.3, col = 2) #the value I used to simulate the data
#Plot posterior density
hist(lambda.store, prob = TRUE, xlab = expression(lambda), main = "Posterior density")
abline(v=0.3, col = 2) #the value I used to simulate the data
mean(lambda.store)
# Set Up MCMC Algorithm ---------------------------------------------------
n.iter <- 10000
lambda.store <- numeric(n.iter) #Store value of Markov chain at end of every iteration
gamma.store <- numeric(n.iter) #Store value of Markov chain at end of every iteration
# Run MCMC Algorithm ------------------------------------------------------
for(i in 2:n.iter){
#Store current value of Markov Chain
lambda.store[i] <- rgamma(10, 95 + gamma.store[i-1])
gamma.store[i]  <- rexp(0.01 + lambda.store[i])
}
warnings()
x <- rexp(20, 0.3)
# Set Up MCMC Algorithm ---------------------------------------------------
n.iter <- 10000
lambda.store <- numeric(n.iter) #Store value of Markov chain at end of every iteration
gamma.store <- numeric(n.iter) #Store value of Markov chain at end of every iteration
# Run MCMC Algorithm ------------------------------------------------------
for(i in 2:n.iter){
#Store current value of Markov Chain
lambda.store[i] <- rgamma(1, 10, 95 + gamma.store[i-1])
gamma.store[i]  <- rexp(1, 0.01 + lambda.store[i])
}
#Plot trace plot (Markov chain values)
plot(lambda.store, type = 'l', xlab = "iteration", ylab = expression(lambda))
plot(gamma.store, type = 'l', xlab = "iteration", ylab = expression(gamma))
#Plot posterior density
hist(lambda.store, prob = TRUE, xlab = expression(lambda), main = "Posterior density")
#Plot posterior density
hist(lambda.store, prob = TRUE, xlab = expression(lambda), main = "Posterior density")
mean(lambda.store) #posterior mean
quantile(lambda.store, c(0.025, 0.975)) #95% CI
hist(gamma.store, prob = TRUE, xlab = expression(lambda), main = "Posterior density")
mean(gamma.store) #posterior mean
quantile(gamma.store, c(0.025, 0.975)) #95% CI
plot(lambda.store, gamma.store)
plot(lambda.store, log(gamma.store))
cor(lambda.store, log(gamma.store))
cor(lambda.store, gamma.store)
plot(lambda.store, (gamma.store))
#Function that evaluates Pareto loglikelihood
log.likelihood <- function(x, beta){
log.value <- length(x)*log(beta) - (beta + 1)*sum(log(x))
return(log.value)
}
# MCMC Sampler ------------------------------------------------------------
#Initialise Values
x <- c(1.019844, 1.043574, 1.360953, 1.049228, 1.491926, 1.192943, 1.323738, 1.262572, 2.034768, 1.451654)
n.iter <- 10000 #number of iterations
beta.current <- 2 #initial value for beta
beta.store <- numeric(n.iter) #empty vecotr to store beta at each iteration
#Run MCMC For Loop
for(i in 1:n.iter){
#Propose prop value for beta
beta.prop <- rnorm(1, beta.current, 0.01)
#Compute current and prop loglikelihood
loglike.prop     <- log.likelihood(x, beta.prop)
loglike.current <- log.likelihood(x, beta.current)
#Compute Log acceptance probability
log.p.acc <- loglike.prop - loglike.current +
dgamma(beta.prop, 1, 0.01, log = TRUE) - dgamma(beta.current, 1, 0.01, log = TRUE)
#Accept/Reject
u <- runif(1)
if(log(u) < log.p.acc){
beta.current <- beta.prop
}
#Store Current Value
beta.store[i] <- beta.current
}
#Plot trace plots
plot(beta.store, type = 'l')
#Investigate posterior
hist(beta.store, freq = FALSE, main = "", xlab = expression(beta))
quantile(beta.store, c(0.025, 0.975))
#Function that evaluates Pareto loglikelihood
log.likelihood <- function(x, beta){
log.value <- length(x)*log(beta) - (beta + 1)*sum(log(x))
return(log.value)
}
# MCMC Sampler ------------------------------------------------------------
#Initialise Values
x <- c(1.019844, 1.043574, 1.360953, 1.049228, 1.491926, 1.192943, 1.323738, 1.262572, 2.034768, 1.451654)
n.iter <- 10000 #number of iterations
beta.current <- 2 #initial value for beta
beta.store <- numeric(n.iter) #empty vecotr to store beta at each iteration
#Run MCMC For Loop
for(i in 1:n.iter){
#Propose prop value for beta
beta.prop <- rnorm(1, beta.current, 0.1)
#Compute current and prop loglikelihood
loglike.prop     <- log.likelihood(x, beta.prop)
loglike.current <- log.likelihood(x, beta.current)
#Compute Log acceptance probability
log.p.acc <- loglike.prop - loglike.current +
dgamma(beta.prop, 1, 0.01, log = TRUE) - dgamma(beta.current, 1, 0.01, log = TRUE)
#Accept/Reject
u <- runif(1)
if(log(u) < log.p.acc){
beta.current <- beta.prop
}
#Store Current Value
beta.store[i] <- beta.current
}
#Plot trace plots
plot(beta.store, type = 'l')
#Investigate posterior
hist(beta.store, freq = FALSE, main = "", xlab = expression(beta))
quantile(beta.store, c(0.025, 0.975))
#Function that evaluates Pareto loglikelihood
log.likelihood <- function(x, beta){
log.value <- length(x)*log(beta) - (beta + 1)*sum(log(x))
return(log.value)
}
# MCMC Sampler ------------------------------------------------------------
#Initialise Values
x <- c(1.019844, 1.043574, 1.360953, 1.049228, 1.491926, 1.192943, 1.323738, 1.262572, 2.034768, 1.451654)
n.iter <- 10000 #number of iterations
beta.current <- 2 #initial value for beta
beta.store <- numeric(n.iter) #empty vecotr to store beta at each iteration
#Run MCMC For Loop
for(i in 1:n.iter){
#Propose prop value for beta
beta.prop <- rnorm(1, beta.current, 0.2)
#Compute current and prop loglikelihood
loglike.prop     <- log.likelihood(x, beta.prop)
loglike.current <- log.likelihood(x, beta.current)
#Compute Log acceptance probability
log.p.acc <- loglike.prop - loglike.current +
dgamma(beta.prop, 1, 0.01, log = TRUE) - dgamma(beta.current, 1, 0.01, log = TRUE)
#Accept/Reject
u <- runif(1)
if(log(u) < log.p.acc){
beta.current <- beta.prop
}
#Store Current Value
beta.store[i] <- beta.current
}
#Plot trace plots
plot(beta.store, type = 'l')
#Function that evaluates Pareto loglikelihood
log.likelihood <- function(x, beta){
log.value <- length(x)*log(beta) - (beta + 1)*sum(log(x))
return(log.value)
}
# MCMC Sampler ------------------------------------------------------------
#Initialise Values
x <- c(1.019844, 1.043574, 1.360953, 1.049228, 1.491926, 1.192943, 1.323738, 1.262572, 2.034768, 1.451654)
n.iter <- 10000 #number of iterations
beta.current <- 2 #initial value for beta
beta.store <- numeric(n.iter) #empty vecotr to store beta at each iteration
#Run MCMC For Loop
for(i in 1:n.iter){
#Propose prop value for beta
beta.prop <- rnorm(1, beta.current, 0.3)
#Compute current and prop loglikelihood
loglike.prop     <- log.likelihood(x, beta.prop)
loglike.current <- log.likelihood(x, beta.current)
#Compute Log acceptance probability
log.p.acc <- loglike.prop - loglike.current +
dgamma(beta.prop, 1, 0.01, log = TRUE) - dgamma(beta.current, 1, 0.01, log = TRUE)
#Accept/Reject
u <- runif(1)
if(log(u) < log.p.acc){
beta.current <- beta.prop
}
#Store Current Value
beta.store[i] <- beta.current
}
#Plot trace plots
plot(beta.store, type = 'l')
#Function that evaluates Pareto loglikelihood
log.likelihood <- function(x, beta){
log.value <- length(x)*log(beta) - (beta + 1)*sum(log(x))
return(log.value)
}
# MCMC Sampler ------------------------------------------------------------
#Initialise Values
x <- c(1.019844, 1.043574, 1.360953, 1.049228, 1.491926, 1.192943, 1.323738, 1.262572, 2.034768, 1.451654)
n.iter <- 10000 #number of iterations
beta.current <- 2 #initial value for beta
beta.store <- numeric(n.iter) #empty vecotr to store beta at each iteration
#Run MCMC For Loop
for(i in 1:n.iter){
#Propose prop value for beta
beta.prop <- rnorm(1, beta.current, 0.5)
#Compute current and prop loglikelihood
loglike.prop     <- log.likelihood(x, beta.prop)
loglike.current <- log.likelihood(x, beta.current)
#Compute Log acceptance probability
log.p.acc <- loglike.prop - loglike.current +
dgamma(beta.prop, 1, 0.01, log = TRUE) - dgamma(beta.current, 1, 0.01, log = TRUE)
#Accept/Reject
u <- runif(1)
if(log(u) < log.p.acc){
beta.current <- beta.prop
}
#Store Current Value
beta.store[i] <- beta.current
}
#Plot trace plots
plot(beta.store, type = 'l')
#Function that evaluates Pareto loglikelihood
log.likelihood <- function(x, beta){
log.value <- length(x)*log(beta) - (beta + 1)*sum(log(x))
return(log.value)
}
# MCMC Sampler ------------------------------------------------------------
#Initialise Values
x <- c(1.019844, 1.043574, 1.360953, 1.049228, 1.491926, 1.192943, 1.323738, 1.262572, 2.034768, 1.451654)
n.iter <- 10000 #number of iterations
beta.current <- 2 #initial value for beta
beta.store <- numeric(n.iter) #empty vecotr to store beta at each iteration
#Run MCMC For Loop
for(i in 1:n.iter){
#Propose prop value for beta
beta.prop <- rnorm(1, beta.current, 0.6)
#Compute current and prop loglikelihood
loglike.prop     <- log.likelihood(x, beta.prop)
loglike.current <- log.likelihood(x, beta.current)
#Compute Log acceptance probability
log.p.acc <- loglike.prop - loglike.current +
dgamma(beta.prop, 1, 0.01, log = TRUE) - dgamma(beta.current, 1, 0.01, log = TRUE)
#Accept/Reject
u <- runif(1)
if(log(u) < log.p.acc){
beta.current <- beta.prop
}
#Store Current Value
beta.store[i] <- beta.current
}
#Function that evaluates Pareto loglikelihood
log.likelihood <- function(x, beta){
log.value <- length(x)*log(beta) - (beta + 1)*sum(log(x))
return(log.value)
}
# MCMC Sampler ------------------------------------------------------------
#Initialise Values
x <- c(1.019844, 1.043574, 1.360953, 1.049228, 1.491926, 1.192943, 1.323738, 1.262572, 2.034768, 1.451654)
n.iter <- 10000 #number of iterations
beta.current <- 2 #initial value for beta
beta.store <- numeric(n.iter) #empty vecotr to store beta at each iteration
#Run MCMC For Loop
for(i in 1:n.iter){
#Propose prop value for beta
beta.prop <- rnorm(1, beta.current, 0.6)
#Compute current and prop loglikelihood
loglike.prop     <- log.likelihood(x, beta.prop)
loglike.current <- log.likelihood(x, beta.current)
#Compute Log acceptance probability
log.p.acc <- loglike.prop - loglike.current +
dgamma(beta.prop, 1, 0.01, log = TRUE) - dgamma(beta.current, 1, 0.01, log = TRUE)
#Accept/Reject
u <- runif(1)
if(log(u) < log.p.acc){
beta.current <- beta.prop
}
#Store Current Value
beta.store[i] <- beta.current
}
#Plot trace plots
plot(beta.store, type = 'l')
#Data --------------------------------------------------------------------------
x <- c(55.06 ,118.84, 6.94, 51.10, 46.69, 62.69, 6.71, 12.84, 53.73, 20.86, 3.91,
53.16, 40.77, 27.27, 72.58, 67.15, 16.00, 48.42, 4.03, 41.99, 48.92,
78.69, 11.30, 273.04, 0.74, 26.02, 21.31, 62.93, 44.89, 165.08)
y <-  c(50.15, 6.47, 45.77, 143.01, 12.53, 12.06, 123.75, 15.74, 4.72, 4.64, 25.88,
8.33, 1.25, 34.60, 7.66, 38.93, 77.16, 23.24, 13.11, 46.73, 143.65, 66.45,
49.79, 46.67, 16.38, 41.19, 3.32, 20.47, 116.15, 31.69)
#Task 1 ------------------------------------------------------------------------
#Function for bootstrap sample and median difference of two paired data sets
bootstrap.median.diff <- function(data.1, data.2){
#Input: Two paired data sets
#Output: Median difference for a bootstrap sample of the data sets
#Description: Takes a bootstrap sample of two paired data sets, then calculates the median difference of the samples.
positions <- sample(1:length(data.1), length(data.1), replace = TRUE) #Sample positions of data points in the vector with replacement
sample.1 <- data.1[positions[1:length(data.1)]] #Obtains data points in first data set from sampled positions
sample.2 <- data.2[positions[1:length(data.2)]] #Obtains data points in second data set from sampled positions
median.diff <- median(sample.1) - median(sample.2) #Finds median difference from both bootstrap samples of the two samples
print(median.diff) #Prints median difference of the two samples.
}
#Task 2 ------------------------------------------------------------------------
set.seed(1)
replicate.median.diff <- replicate(n = 10000, bootstrap.median.diff(x, y)) #Produces 10000 median differences from bootstrap samples of x and y
head(replicate.median.diff) #First 6 median differences produced
#Task 3 ------------------------------------------------------------------------
#Plotting distribution of median differences
hist(replicate.median.diff, xlab = "Median Difference in Time", main = "Distribution of 10,000 Bootstrap Sampled Median Differences in Time")
#Mean and Variance of median differences
mean(replicate.median.diff) #Mean of the 10000 median differences
var(replicate.median.diff) #Variance of the 10000 median differences
x <- c(55.06 ,118.84, 6.94, 51.10, 46.69, 62.69, 6.71, 12.84, 53.73, 20.86, 3.91,
53.16, 40.77, 27.27, 72.58, 67.15, 16.00, 48.42, 4.03, 41.99, 48.92,
78.69, 11.30, 273.04, 0.74, 26.02, 21.31, 62.93, 44.89, 165.08)
y <-  c(50.15, 6.47, 45.77, 143.01, 12.53, 12.06, 123.75, 15.74, 4.72, 4.64, 25.88,
8.33, 1.25, 34.60, 7.66, 38.93, 77.16, 23.24, 13.11, 46.73, 143.65, 66.45,
49.79, 46.67, 16.38, 41.19, 3.32, 20.47, 116.15, 31.69)
#this function generates the bootstrap samples and then calculates the median
#differences in strategies
boot_strap <- function(x, y){
# Generate the indexes for the boot strap sample
b <- sample(1:30, size = 30, replace = T)
# Set up vector z to hold the differences in x and y value
z <- numeric(length = 30)
for (i in 1:30){
# For each index in b, store the difference of the corresponding x & y values
z[i] <- x[b[i]] - y[b[i]]
}
# Built in median generating function
z_median <- median(z)
return(z_median)
}
#sets seed to 1
set.seed(1)
# this runs the function 10,000 times storing the result
med_results <- replicate(10000, boot_strap(x, y))
#plot the median differences on a histogram
hist(med_results,
main = "Median time difference \n between strat X and strat y",
xlab = "Time difference (X - Y)",
xlim = c(-40, 60),
ylim = c(0, 2000))
#calculate mean and variance using built in r functions
diff_mean <- mean(med_results)
diff_var <- var(med_results)
#Data
x = c(55.06 ,118.84, 6.94, 51.10, 46.69, 62.69, 6.71, 12.84, 53.73, 20.86, 3.91,
53.16, 40.77, 27.27, 72.58, 67.15, 16.00, 48.42, 4.03, 41.99, 48.92,
78.69, 11.30, 273.04, 0.74, 26.02, 21.31, 62.93, 44.89, 165.08)
y =  c(50.15, 6.47, 45.77, 143.01, 12.53, 12.06, 123.75, 15.74, 4.72, 4.64, 25.88,
8.33, 1.25, 34.60, 7.66, 38.93, 77.16, 23.24, 13.11, 46.73, 143.65, 66.45,
49.79, 46.67, 16.38, 41.19, 3.32, 20.47, 116.15, 31.69)
#Build median difference function
Median_difference = function(x,y){
generate_sample = sample(length(x), replace = TRUE)     #Generate samples
time_x = x[generate_sample]     #Find the corresponding time of method X
time_y = y[generate_sample]     #Find the corresponding time of method Y
median_diff = median(time_x - time_y)     #Calculate the value of median difference between methods X and Y
return(median_diff)     #Return the value of median difference
}
set.seed(1)     #set seed
result = replicate(n = 10000, expr = Median_difference(x,y))     #Call function 10000 times
mean_median = mean(result)     # Calculate the mean of median difference
cat("The mean of median differences is", mean_median)     #Print out the value of mean of median difference
var_median = var(result)       # Calculate the variance of median difference
cat("The variance of median differences:", var_median)    #Print out the value of variance of median difference
#Plot the distribution of median difference by using histogram
hist(result, breaks = 30, main = "Distribution of median difference", xlab = "Median difference (seconds)", ylab = "Frequency", col = "lightblue", border = "black")
abline(v = mean_median, col = "red", lwd = 2)     # Adding a vertical line to represent the position of the mean
text(mean_median, 1200, paste("Mean:", round(mean_median,2)), col = "blue")     #Label the value of mean on the histogram
text(mean_median, 1000, paste("Variance:", round(var_median,2)), col = "blue")     #Label the value of variance on the histogram
#Plot the distribution of median difference by using density estimate
plot(density(result), main = "Distribution of median difference", xlab = "Median difference (seconds)", ylab = "Density")
abline(v = mean_median, col = "red", lwd = 1.5)     # Adding a vertical line to represent the position of the mean
text(mean_median, 0.015, paste("Mean:", round(mean_median,2)), col = "blue")     #Label the value of mean on the density estimate
text(mean_median, 0.010, paste("Variance:", round(var_median,2)), col = "blue")     #Label the value of variance on the density estimate
#Plot the distribution of median difference by using histogram
hist(result, breaks = 30, main = "Distribution of median difference", xlab = "Median difference (seconds)", ylab = "Frequency", col = "lightblue", border = "black")
abline(v = mean_median, col = "red", lwd = 2)     # Adding a vertical line to represent the position of the mean
text(mean_median, 1200, paste("Mean:", round(mean_median,2)), col = "blue")     #Label the value of mean on the histogram
text(mean_median, 1000, paste("Variance:", round(var_median,2)), col = "blue")     #Label the value of variance on the histogram
#Plot the distribution of median difference by using density estimate
plot(density(result), main = "Distribution of median difference", xlab = "Median difference (seconds)", ylab = "Density")
abline(v = mean_median, col = "red", lwd = 1.5)     # Adding a vertical line to represent the position of the mean
text(mean_median, 0.015, paste("Mean:", round(mean_median,2)), col = "blue")     #Label the value of mean on the density estimate
text(mean_median, 0.010, paste("Variance:", round(var_median,2)), col = "blue")     #Label the value of variance on the density estimate
#Input current method X and new method Y----------------------------------------
x <- c(55.06 ,118.84, 6.94, 51.10, 46.69, 62.69, 6.71, 12.84, 53.73, 20.86, 3.91,
53.16, 40.77, 27.27, 72.58, 67.15, 16.00, 48.42, 4.03, 41.99, 48.92,
78.69, 11.30, 273.04, 0.74, 26.02, 21.31, 62.93, 44.89, 165.08)
y <- c(50.15, 6.47, 45.77, 143.01, 12.53, 12.06, 123.75, 15.74, 4.72, 4.64, 25.88,
8.33, 1.25, 34.60, 7.66, 38.93, 77.16, 23.24, 13.11, 46.73, 143.65, 66.45,
49.79, 46.67, 16.38, 41.19, 3.32, 20.47, 116.15, 31.69)
#define the bootstrap sample function-------------------------------------------
bootstrap_sample <- function(x, y){
indices <- sample(1:length(x), replace = TRUE) #generate indices for resampling
x_sample <- x[indices] #resample the observations based on indices
y_sample <- y[indices] #resample the observations based on indices
median_diff <- median(x_sample - y_sample) #compute the median difference
return(median_diff)
}
#set seed to 1------------------------------------------------------------------
set.seed(1)
# Generate 10000 times in bootstrap_sample function-----------------------------
bootstrap <- replicate(10000, bootstrap_sample(x, y))
#Plot the distribution of the median differences--------------------------------
hist(bootstrap, main = "Distribution of Median Differences",
xlab = "Median Difference", ylab = "Frequency", col="cadetblue1", breaks = 20)
#Calculate the mean and the variance of the median differences------------------
mean_bootstrap <- mean(bootstrap)
print(paste('mean of the distribution =', mean_bootstrap))
variance_bootstrap <- var(bootstrap)
print(paste('variance of the distribution =', variance_bootstrap))
